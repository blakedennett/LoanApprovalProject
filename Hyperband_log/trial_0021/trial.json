{"trial_id": "0021", "hyperparameters": {"space": [{"class_name": "Choice", "config": {"name": "activation", "default": "relu", "conditions": [], "values": ["relu", "tanh", "selu", "elu"], "ordered": false}}, {"class_name": "Int", "config": {"name": "num_layers", "default": null, "conditions": [], "min_value": 1, "max_value": 3, "step": 1, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "layer1", "default": null, "conditions": [], "min_value": 15, "max_value": 315, "step": 30, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "dropout1", "default": 0.0, "conditions": [], "values": [0.0, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}, {"class_name": "Choice", "config": {"name": "output_activation", "default": "softmax", "conditions": [], "values": ["softmax", "sigmoid", "linear"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "metric", "default": "accuracy", "conditions": [], "values": ["accuracy", "auc", "precision", "recall"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "optimizer", "default": "adam", "conditions": [], "values": ["adam", "sgd", "rmsprop", "Adadelta", "Adafactor", "Adagrad", "Adamax", "Nadam", "Ftrl", "AdamW", "Lion", "Optimizer"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "reduction", "default": "sum", "conditions": [], "values": ["sum", "sum_over_batch_size", "auto", "none"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "learning_rate", "default": 0.1, "conditions": [], "values": [0.1, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}, {"class_name": "Int", "config": {"name": "layer2", "default": null, "conditions": [], "min_value": 15, "max_value": 315, "step": 30, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "dropout2", "default": 0.0, "conditions": [], "values": [0.0, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}, {"class_name": "Int", "config": {"name": "layer3", "default": null, "conditions": [], "min_value": 15, "max_value": 315, "step": 30, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "dropout3", "default": 0.0, "conditions": [], "values": [0.0, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}], "values": {"activation": "relu", "num_layers": 2, "layer1": 225, "dropout1": 0.0001, "output_activation": "softmax", "metric": "accuracy", "optimizer": "Adafactor", "reduction": "sum_over_batch_size", "learning_rate": 0.01, "layer2": 285, "dropout2": 0.0, "layer3": 165, "dropout3": 0.01, "tuner/epochs": 20, "tuner/initial_epoch": 0, "tuner/bracket": 0, "tuner/round": 0}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\", line 425, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 214, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 144, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"c:\\Users\\Blake Dennett\\Downloads\\Summer2023\\NeuralNetwork.py\", line 126, in on_epoch_end\n    f1 = f1_score(y_val, y_pred)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1136, in f1_score\n    return fbeta_score(\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1277, in fbeta_score\n    _, _, f, _ = precision_recall_fscore_support(\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1563, in precision_recall_fscore_support\n    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1364, in _check_set_wise_labels\n    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 86, in _check_targets\n    type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 332, in type_of_target\n    _assert_all_finite(y, input_name=input_name)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 146, in _assert_all_finite\n    raise ValueError(msg_err)\nValueError: Input y_pred contains NaN.\n"}