{"trial_id": "0001", "hyperparameters": {"space": [{"class_name": "Choice", "config": {"name": "activation", "default": "relu", "conditions": [], "values": ["relu", "tanh", "selu", "elu"], "ordered": false}}, {"class_name": "Int", "config": {"name": "num_layers", "default": null, "conditions": [], "min_value": 1, "max_value": 3, "step": 1, "sampling": "linear"}}, {"class_name": "Int", "config": {"name": "layer1", "default": null, "conditions": [], "min_value": 15, "max_value": 315, "step": 30, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "dropout1", "default": 0.0, "conditions": [], "values": [0.0, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}, {"class_name": "Choice", "config": {"name": "output_activation", "default": "softmax", "conditions": [], "values": ["softmax", "sigmoid", "linear"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "metric", "default": "accuracy", "conditions": [], "values": ["accuracy", "auc", "precision", "recall"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "optimizer", "default": "adam", "conditions": [], "values": ["adam", "sgd", "rmsprop", "Adadelta", "Adafactor", "Adagrad", "Adamax", "Nadam", "Ftrl", "AdamW", "Lion", "Optimizer"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "reduction", "default": "sum", "conditions": [], "values": ["sum", "sum_over_batch_size", "auto", "none"], "ordered": false}}, {"class_name": "Choice", "config": {"name": "learning_rate", "default": 0.1, "conditions": [], "values": [0.1, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}, {"class_name": "Int", "config": {"name": "layer2", "default": null, "conditions": [], "min_value": 15, "max_value": 315, "step": 30, "sampling": "linear"}}, {"class_name": "Choice", "config": {"name": "dropout2", "default": 0.0, "conditions": [], "values": [0.0, 0.01, 0.001, 0.0001, 1e-05], "ordered": true}}], "values": {"activation": "tanh", "num_layers": 2, "layer1": 15, "dropout1": 0.01, "output_activation": "softmax", "metric": "recall", "optimizer": "Optimizer", "reduction": "sum_over_batch_size", "learning_rate": 0.1, "layer2": 225, "dropout2": 0.0, "tuner/epochs": 3, "tuner/initial_epoch": 0, "tuner/bracket": 2, "tuner/round": 0}}, "metrics": {"metrics": {}}, "score": null, "best_step": 0, "status": "FAILED", "message": "Traceback (most recent call last):\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\", line 425, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 213, in _build_and_fit_model\n    model = self._try_build(hp)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\", line 428, in _build_hypermodel\n    model = super()._build_hypermodel(hp)\n  File \"C:\\Users\\Blake Dennett\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"c:\\Users\\Blake Dennett\\Downloads\\Summer2023\\NeuralNetwork.py\", line 95, in build_model\n    model.compile(loss=BinaryCrossentropy(reduction=hp_reduction), optimizer=str_to_optimizer(hp_optimizer), metrics=[metric_to_use])\n  File \"c:\\Users\\Blake Dennett\\Downloads\\Summer2023\\NeuralNetwork.py\", line 64, in str_to_optimizer\n    return Optimizer()\nTypeError: Optimizer.__init__() missing 1 required positional argument: 'name'\n"}